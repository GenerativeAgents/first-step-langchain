# このプログラムについて

ユーザーからの質問に対して、ネットの検索とローカルファイルの検索を使って回答する AI エージェントのサンプルプログラムです。

# 注意

- このソースコードは動作をご説明するための簡易的なものであり、動作を保証するものではありません。あらかじめご了承ください。

- macOS、VS Code にて動作を確認しております。環境によっては手順が変わることがありますので、ご了承ください。

- 質問の内容や検索対象にするローカルファイルの内容は、LLM のサービスや LangSmith のサービスへ送られる形になります。セキュリティ上問題のないことを確認の上でご利用ください。

# インストールの手順

1. 以下のライブラリやアプリケーションをインストールしてください。

- Git
- uv
- VS Code

2. VS Codeで、このリポジトリをクローンして開いてください。

# 設定の手順

- 利用する LLM は、`app.py`の「# ③ 利用 LLM を選択」の部分にある次の 3 種類から選択する形になっています。それぞれの LLM ベンダーで利用登録をして API-KEY を発行し、後述の`.env`ファイルに記述してください。なお、使用しないモデルは「# ③ 利用 LLM を選択」の該当行を削除すれば、その API-KEY の取得も不要です。

```
  "anthropic:claude-sonnet-4-0",
  "openai:gpt-4.1-mini",
  "google_genai:gemini-2.5-flash",
```

- ネットの検索は Tavily のサービスを利用しています。無料プランがありますので、https://tavily.com/ で利用登録して API-KEY を発行し、後述の`.env`ファイルに記述してください。

- ローカル検索の対象は docs ディレクトリ以下にあるファイルです。docx ファイルと pdf ファイルで動作を確認しています。それ以外の種類のファイルを配置する際は、追加のライブラリのインストールが必要になる場合があります。

- ローカルファイルの検索には、オンメモリのベクトルデータベースを使っており、アプリ起動時にインデックスを作成します。そのため、大量のファイルは処理できません。起動時間が遅くなったり、メモリが不足することがあります。必要に応じて、ファイルベースで動作する実装に修正してください。

- AI エージェントの内部をトレースするために、LangSmith のサービスを利用しています。無料プランがありますので、https://www.langchain.com/langsmith で利用登録して、API-KEY を発行し、後述の`.env`ファイルに記述してください。なお、LangSmith を使わなくても動作します。その場合は、`.env`ファイルで、`LANGCHAIN_TRACING_V2=false`と設定してください。この場合、API-KEY の取得も不要です。

- `.env.template`ファイルのファイル名を`.env`に変更し、中に各種 API-KEY を記述してください。たとえば OpenAI から取得した API-KEY が`sk-proj-abcde-12345`（実際はもっと長いです）の場合は、以下のように記述してください。また、使用しない API-KEY に関しては、該当する行ごと削除してください。

```
OPENAI_API_KEY=sk-proj-abcde-12345
```

# 実行方法

- VS Code のターミナルで`make streamlit`を実行するとサーバーが起動し、ブラウザで`localhost:8080`にアクセスすると利用できます。
- 初回の実行時は、uv により必要なライブラリがインストールされるため時間がかかります。
- 終了は`Ctrl`+`C`です。
